{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 追加事例1 欠陥・疾患判定の自動化 (2値分類と再現率)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 共通事前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日本語化ライブラリ導入\n",
    "!pip install japanize-matplotlib | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共通事前処理\n",
    "\n",
    "# 余分なワーニングを非表示にする\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 必要ライブラリのimport\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# matplotlib日本語化対応\n",
    "import japanize_matplotlib\n",
    "\n",
    "# データフレーム表示用関数\n",
    "from IPython.display import display\n",
    "\n",
    "# 表示オプション調整\n",
    "# numpyの浮動小数点の表示精度\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "# pandasでの浮動小数点の表示精度\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "# データフレームですべての項目を表示\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "\n",
    "# グラフのデフォルトフォント指定\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "\n",
    "# 乱数の種\n",
    "random_seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混同行列表示用関数\n",
    "\n",
    "def make_cm(matrix, columns):\n",
    "    # matrix numpy配列\n",
    "    \n",
    "    # columns 項目名リスト\n",
    "    n = len(columns)\n",
    "    \n",
    "    # '正解データ'をn回繰り返すリスト生成\n",
    "    act = ['正解データ'] * n\n",
    "    pred = ['予測結果'] * n\n",
    "    \n",
    "    #データフレーム生成\n",
    "    cm = pd.DataFrame(matrix, \n",
    "        columns=[pred, columns], index=[act, columns])\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1.4 データ読み込みからデータ確認まで"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 項目メモ\n",
    "\n",
    "#### age\n",
    "年齢\n",
    "\n",
    "#### sex\n",
    "性別\n",
    "* 1: 男性\n",
    "* 0: 女性\n",
    "\n",
    "#### cp\n",
    "胸痛種別\n",
    "* 1：典型的な狭心症\n",
    "* 2：非定型狭心症\n",
    "* 3：非狭心痛\n",
    "* 4：無症候性 \n",
    "\n",
    "#### trestbps\n",
    "安静時血圧  \n",
    "（入院時のmm Hg単位）\n",
    "    \n",
    "#### chol\n",
    "血清コレステロール  \n",
    "（mg / dl）\n",
    "\n",
    "#### fbs\n",
    "空腹時血糖   \n",
    "(> 120 (mg / dl）)\n",
    "* 1 真\n",
    "* 0 偽\n",
    "\n",
    "#### restecg\n",
    "安静時心電図\n",
    " \n",
    "* 0：通常\n",
    "* 1：ST-T波異常（T波反転および/またはST上昇または抑圧> 0.05 mV）\n",
    "* 2：左心室肥大の可能性あり\n",
    "\n",
    "#### thalach\n",
    "最大心拍数\n",
    "\n",
    "#### exang\n",
    "運動誘発性狭心症\n",
    "* 1  はい\n",
    "* 0  いいえ\n",
    "    \n",
    "#### oldpeak\n",
    "ST低下    \n",
    "(運動により誘発される安静時と比較したST低下)\n",
    "\n",
    "#### slope\n",
    " STセグメント勾配  \n",
    "(ピーク運動STセグメント勾配)\n",
    "* 1 上昇\n",
    "* 2 フラット  \n",
    "* 3 下降\n",
    "\n",
    "#### ca \n",
    "主要血管数  \n",
    "(X線透視撮影で着色された主要な血管数（0〜3）)\n",
    "\n",
    "\n",
    "#### thal\n",
    "タール  \n",
    "(タリウム心臓スキャンの結果) \n",
    "* 3: 通常\n",
    "* 6 : 修正された欠陥\n",
    "* 7 : 回復可能な欠陥\n",
    "\n",
    "\n",
    "#### num (目的変数)\n",
    "心臓病診断  \n",
    " （血管造影の状態）\n",
    "* 0: 所見なし\n",
    "* 1: 所見あり"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 心疾患公開データ読み込み\n",
    "\n",
    "columns = [\n",
    "    '年齢', '性別', '胸痛種別', '安静時血圧',  '血清コレステロール',\n",
    "    '空腹時血糖値', '安静時心電図',  '最大心拍数',  '運動誘発性狭心症',\n",
    "    'ST低下', 'STセグメント勾配', '主要血管数', 'タール', '心臓病診断'\n",
    "]\n",
    "\n",
    "# 公開データセットのURL\n",
    "url_hu = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "heart-disease/processed.hungarian.data'\n",
    "\n",
    "# データフレームへの取り込み\n",
    "# 欠損値は'?'で表現されているので、読み込み時にPythonのNaNに変換する\n",
    "df_hu = pd.read_csv(url_hu, header=None, names=columns, na_values='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データ確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ全体の確認\n",
    "display(df_hu.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データ件数と項目数確認\n",
    "print(df_hu.shape)\n",
    "print()\n",
    "\n",
    "# 「心臓病診断」の値の分布確認\n",
    "print(df_hu['心臓病診断'].value_counts())\n",
    "print()\n",
    "\n",
    "# 所見あり比率\n",
    "rate = df_hu['心臓病診断'].value_counts()[1]/len(df_hu)\n",
    "print(f'有症率: {rate:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒストグラム表示\n",
    "\n",
    "# グラフのサイズ調整のためのおまじない\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (12, 12)\n",
    "\n",
    "# データフレームの数値項目でヒストグラム表示\n",
    "df_hu.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値確認\n",
    "print(df_hu.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1.5 データ前処理とデータ分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データ前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 欠損値対応方針\n",
    "\n",
    "* 安静時血圧: 平均値\n",
    "*  血清コレステロール: 平均値\n",
    "* 空腹時血糖値: 0\n",
    "* 安静時心電図: 0\n",
    "* 最大心拍数: 平均値\n",
    "* 運動誘発性狭心症: 0   \n",
    "* STセグメント勾配: 2  \n",
    "----    \n",
    "* 主要血管数: 項目ごと落とす\n",
    "* タール: 項目ごと落とす\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均値の計算\n",
    "ave1 = df_hu['安静時血圧'].mean()\n",
    "ave2 = df_hu['血清コレステロール'].mean()\n",
    "ave3 = df_hu['最大心拍数'].mean()\n",
    "\n",
    "# 結果確認\n",
    "print(f'安静時血圧: {ave1:.1f}  血清コレステロール: {ave2:.1f}   最大心拍数:{ave3:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値の置換\n",
    "df2 = df_hu.fillna(\n",
    "    {'安静時血圧': ave1,\n",
    "    '血清コレステロール': ave2,\n",
    "    '空腹時血糖値': 0,\n",
    "    '安静時心電図': 0,\n",
    "    '最大心拍数': ave3,\n",
    "    '運動誘発性狭心症': 0,\n",
    "    'STセグメント勾配': 2}\n",
    ")\n",
    "\n",
    "# 列の削除\n",
    "df3 = df2.drop(['主要血管数', 'タール'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 結果確認\n",
    "print(df3.isnull().sum())\n",
    "display(df3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データ分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力データと正解データの分離\n",
    "x = df3.drop('心臓病診断', axis=1)\n",
    "y = df3['心臓病診断'].values\n",
    "\n",
    "# 訓練データと検証データの分離\n",
    "test_size=0.40\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "  x, y, test_size=test_size, random_state=random_seed,\n",
    "  stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1.6 アルゴリズムの選定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### アルゴリズム選定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 候補アルゴリズムのリスト化\n",
    "\n",
    "# ロジスティック回帰 (4.3.3)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algorithm1 = LogisticRegression(random_state=random_seed)\n",
    "\n",
    "# 決定木 (4.3.6)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "algorithm2 = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "# ランダムフォレスト (4.3.7)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "algorithm3 = RandomForestClassifier(random_state=random_seed)\n",
    "\n",
    "# XGBoost (4.3.8)\n",
    "from xgboost import XGBClassifier\n",
    "algorithm4 = XGBClassifier(random_state=random_seed)\n",
    "\n",
    "algorithms = [algorithm1, algorithm2, algorithm3, algorithm4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交差検定法を用いて最適なアルゴリズムの選定\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "stratifiedkfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "for algorithm in algorithms:\n",
    "    # 交差検定法の実行\n",
    "    scores = cross_val_score(algorithm , x_train, y_train,\n",
    "        cv=stratifiedkfold, scoring='roc_auc')\n",
    "    score = scores.mean()\n",
    "    name = algorithm.__class__.__name__\n",
    "    print(f'平均スコア: {score:.4f}  個別スコア: {scores}  {name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はランダムフォレストが一番性能がよかったので以降のアルゴリズムとして利用\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1.7 学習・予測・評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アルゴリズム選定\n",
    "# ランダムフォレストを選定\n",
    "algorithm = RandomForestClassifier(random_state=random_seed)\n",
    "\n",
    "# 学習\n",
    "algorithm.fit(x_train, y_train)\n",
    "\n",
    "# 予測\n",
    "y_pred = algorithm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価\n",
    "\n",
    "# 混同行列を出力\n",
    "from sklearn.metrics import confusion_matrix\n",
    "df_matrix = make_cm(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    ['所見なし', '所見あり'])\n",
    "display(df_matrix)\n",
    "\n",
    "# 適合率、再現率、F値を計算\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(y_test, \n",
    "    y_pred, average='binary')\n",
    "print(f'適合率: {precision:.4f}  再現率: {recall:.4f}  F値: {fscore:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1.8 チューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確率値の度数分布グラフ\n",
    "\n",
    "# y=1の確率値取得\n",
    "y_proba1= algorithm.predict_proba(x_test)[:,1]\n",
    "\n",
    "# y_test=0 と y_test=1 でデータ分割\n",
    "y0 = y_proba1[y_test==0]\n",
    "y1 = y_proba1[y_test==1]\n",
    "\n",
    "# 散布図描画\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title('確率値の度数分布')\n",
    "sns.distplot(y1, kde=False, norm_hist=True,\n",
    "    bins=10,color='b', label='所見あり')\n",
    "sns.distplot(y0, kde=False, norm_hist=True,\n",
    "    bins=10,color='k', label='所見なし')\n",
    "plt.xlabel('確率値')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 閾値見直し"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict_proba関数を利用して、閾値0.5以外の場合の予測をする\n",
    "(4.4節参照)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 閾値を変更した場合の予測関数の定義\n",
    "def pred(algorithm, x, thres):\n",
    "    # 確率値の取得(行列)\n",
    "    y_proba = algorithm.predict_proba(x)\n",
    "    \n",
    "    # 予測結果1の確率値\n",
    "    y_proba1 =  y_proba[:,1]\n",
    "    \n",
    "    # 予測結果1の確率値 > 閾値\n",
    "    y_pred = (y_proba1 > thres).astype(int)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 閾値を0.05刻みに変化させて、適合率, 再現率, F値を計算する\n",
    "thres_list = np.arange(0.5, 0, -0.05)\n",
    "\n",
    "for thres in thres_list:\n",
    "    y_pred2 = pred(algorithm, x_test, thres)\n",
    "    pred_sum =  y_pred2.sum()\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(\n",
    "        y_test, y_pred2, average='binary')\n",
    "    print(f'閾値: {thres:.2f} 合計: {pred_sum}  適合率: {precision:.4f}\\\n",
    "  再現率: {recall:.4f}  F値: {fscore:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再現率重視で閾値を0.25にする\n",
    "y_final = pred(algorithm, x_test, 0.25)\n",
    "\n",
    "# 混同行列を出力\n",
    "from sklearn.metrics import confusion_matrix\n",
    "df_matrix4 = make_cm(\n",
    "    confusion_matrix(y_test, y_final),\n",
    "    ['所見なし', '所見あり'])\n",
    "display(df_matrix4)\n",
    "\n",
    "# 適合率、再現率、F値を計算\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(\n",
    "    y_test, y_final, average='binary')\n",
    "print(f'適合率: {precision:.4f}  再現率: {recall:.4f}  F値: {fscore:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
